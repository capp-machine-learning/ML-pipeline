{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6cfec9fbf45d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "import graphviz\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for reading the data (hard-coded for now)\n",
    "def read_data(filename):\n",
    "    \n",
    "    _, ext = os.path.splitext(filename)\n",
    "    \n",
    "    if ext == '.csv':\n",
    "        df = pd.read_csv(filename, index_col=0)\n",
    "    elif ext == '.xls':\n",
    "        df = pd.read_excel(filename, header=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data\n",
    "\n",
    "First, we will read the dataset and the data dictionary for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read 'credit-data.csv'\n",
    "df = read_data('data/credit-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/data-dictionary.xls\n",
    "data_dict = read_data('data/data-dictionary.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "We will look at distributions of variables, correlations between them, and summarize data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Distribution of the Outcome Variable\n",
    "\n",
    "The Outcome Variable: __*SeriousDlgin2yrs*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SeriousDlqin2yrs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SeriousDlqin2yrs'].value_counts().plot('bar', rot=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are an imbalance in the outcome variable. Specifically, there are far more people who experienced 90 days past due delinquency or worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "Now we should look at the number of missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nan_df(df):\n",
    "    \n",
    "    nan = df.isna().sum()\n",
    "    nan_perc = round(100 * nan / len(df.index), 2)\n",
    "    nan_df = pd.concat([nan, nan_perc], axis=1)\n",
    "    nan_df = nan_df.rename(columns = {0: 'NaN', 1: 'Percent of NaN'})\n",
    "    nan_df = nan_df.sort_values(by=['Percent of NaN'], ascending=False)\n",
    "    \n",
    "    return nan_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the missing data\n",
    "nan_df = generate_nan_df(df)\n",
    "nan_df.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that there are a lot of missing data for __MonthlyIncome__ and __NumberOfDependents__.\n",
    "- Therefore, we probably do not want to simply drop all missing data.\n",
    "\n",
    "First, we will look at the distribution of __MonthlyIncome__ and __NumberOfDependents__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_boxplots(df, columns):\n",
    "    \n",
    "    for column in columns:\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(15, 5))\n",
    "        ax = sns.boxplot(x=df[column])\n",
    "        \n",
    "        # if kurtosis is beyond -3 and 3, log scale the x axis.\n",
    "        if abs(df[column].kurt()) > 3:\n",
    "            ax.set_xscale('log')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_boxplots(df, ['MonthlyIncome', 'NumberOfDependents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from these boxplots, the distribution of __MonthlyIncome__ is very skewed.\n",
    "- For __MonthlyIncome__, which is very *skewed*, we will use median to impute NaN.\n",
    "- For __NumberOfDependents__, we will use mean to impute NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_data(df, columns):\n",
    "    \n",
    "    for column in columns:\n",
    "        if abs(df[column].kurt()) > 3:\n",
    "            cond = df[column].median()\n",
    "        else:\n",
    "            cond = df[column].mean()\n",
    "        estimate = round(cond)\n",
    "        df[column] = df[column].fillna(estimate)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = impute_missing_data(df, ['MonthlyIncome', 'NumberOfDependents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types\n",
    "\n",
    "Since we finally have a complete dataset, we will make sure if the dtype of each columns is correct based on the data dictionary we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most of the columns, the dtype looks like right. However, __NumberOfDependents__ should be in integer; we will change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NumberOfDependents'] = df['NumberOfDependents'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations between Variables\n",
    "\n",
    "Next, we will examine correlations between variables to detect any patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_corr_heatmap(df):\n",
    "\n",
    "    # compute correlation\n",
    "    corr = df.corr()\n",
    "    \n",
    "    # generate a mask for the upper triangle\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    \n",
    "    # create figure and plot\n",
    "    f, ax = plt.subplots(figsize=(15, 5))\n",
    "    \n",
    "    # Generate a diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "    sns.heatmap(corr, mask=mask, annot=True, fmt='.2f', cmap=cmap, linewidths=.5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_corr_heatmap(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this heatmap, we can see that the following variables:\n",
    "- __NumberOfTime30-59DaysPastDueNotWorse__,\n",
    "- __NumberOfTimes90DaysLate__,\n",
    "- __NumberOfTime60-89DaysPastDueNotWorse__\n",
    "\n",
    "have extremely high correlations amongst one another (0.98 - 0.99).\n",
    "\n",
    "We will drop the following variables:\n",
    "- __NumberOfTime30-59DaysPastDueNotWorse__,\n",
    "- __NumberOfTime60-89DaysPastDueNotWorse__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_variables(df, columns):\n",
    "    \n",
    "    df = df.drop(labels=columns, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnecessary_vars = ['NumberOfTime30-59DaysPastDueNotWorse', 'NumberOfTime60-89DaysPastDueNotWorse']\n",
    "df = drop_variables(df, unnecessary_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_corr_heatmap(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Outliers\n",
    "\n",
    "Next, we will try to find outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_iqr_outliers(df, column, weight=1.5):\n",
    "\n",
    "    data = df[column]\n",
    "    quantile_25, quantile_75 = np.percentile(data, [25, 75])\n",
    "    iqr = quantile_75 - quantile_25\n",
    "    iqr_weight = iqr * weight\n",
    "    lowest = quantile_25 - iqr_weight\n",
    "    highest = quantile_75 + iqr_weight\n",
    "    outlier_ind = np.where((data < lowest) | (data > highest))\n",
    "        \n",
    "    return outlier_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_outliers(df, columns):\n",
    "    \n",
    "    for column in columns:\n",
    "        f, ax = plt.subplots(figsize=(15, 5))\n",
    "        df.iloc[find_iqr_outliers(df, column)][column].hist(bins=25)\n",
    "        plt.xlabel(column)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at the following variables (selected based on the correlation with the outcome variable) and check if they have any outliers.\n",
    "- __age__\n",
    "- __NumberOfTimes90DaysLate__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_outliers(df, ['age', 'NumberOfTimes90DaysLate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Features/Predictors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NumberOfDependents'].value_counts().plot('bar', rot=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_category(age):\n",
    "    \n",
    "    # bins based on Consumer Financial Protection Bureau\n",
    "    if age < 30:\n",
    "        cat = 1\n",
    "    elif age <= 44:\n",
    "        cat = 2\n",
    "    elif age <= 64:\n",
    "        cat = 3\n",
    "    else:\n",
    "        cat = 4\n",
    "    \n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dependent_dummy(num_of_dependent):\n",
    "    \n",
    "    if num_of_dependent == 0:\n",
    "        cat = 0\n",
    "    elif num_of_dependent >= 1:\n",
    "        cat = 1\n",
    "    \n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_age(df):\n",
    "    \n",
    "    df['age_cat'] = df['age'].apply(lambda x: get_age_category(x))\n",
    "    df = df.drop(labels=['age'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_dependent(df):\n",
    "    \n",
    "    df['dep_cat'] = df['NumberOfDependents'].apply(lambda x: get_dependent_dummy(x))\n",
    "    df = df.drop(labels=['NumberOfDependents'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = discretize_age(df)\n",
    "test_df = discretize_dependent(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dummy(df, variable):\n",
    "    \n",
    "    df = pd.get_dummies(df, columns=[variable])\n",
    "    df = df.drop(labels=['dep_cat'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_dummy(df, 'dep_cat')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Classifier\n",
    "\n",
    "We will build a classifier with __*DecisionTreeClassifier*__.\n",
    "\n",
    "1. Split the dataset into y_df (Outcome set), X_df (Feature set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = df[['SeriousDlqin2yrs']]\n",
    "X_df = df.drop(labels=['SeriousDlqin2yrs'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Split the outcome set and feature set into training and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Train the Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_loan = DecisionTreeClassifier(criterion='entropy', random_state=156)\n",
    "dt_loan.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Visualize the trained Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(dt_loan, out_file=\"tree.dot\", class_names=['Delinquent', 'Not Delinquent'], feature_names=X_train.columns.tolist(), impurity=True, filled=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SeriousDlqin2yrs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df, col='SeriousDlqin2yrs')\n",
    "g.map(plt.hist, 'age', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df, col='SeriousDlqin2yrs')\n",
    "g.map(plt.hist, 'NumberOfDependents', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.NumberOfDependents.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
